{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Given any high impact bug, identify its priority.\n",
    "\n",
    "Methods in research of Software Engineering focus on predicting, localizing, and triaging bugs, but do not consider their impact or weight on the users and on the developers.\n",
    "\n",
    "For this reason, we want to distinguish different kinds of bugs by placing in them in different priority categories: **Critical**, **Blocker**, **Major**, **Minor**, **Trivial**.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Data](#data)<br>\n",
    "    1.1. [Data Extraction](#data-extraction)<br>\n",
    "    1.2. [Manual Feature Selection](#manual-feature-selection)<br>\n",
    "    1.3. [Data Cleaning](#data-cleaning)<br>\n",
    "    1.4. [Generating New Features](#generating-new-features)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.1. [Sentiment Analysis](#sentiment-analysis)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.2. [Fix Duration](#fix-duration)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.3. [Quantify Features](#quantify-features)<br>\n",
    "\n",
    "2. [Implementation](#implementation)<br>\n",
    "3. [Evaluation](#evaluation)<br>\n",
    "4. [Conclusion](#conclusion)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Extraction\n",
    "import csv\n",
    "\n",
    "# SentiStrength\n",
    "import subprocess\n",
    "import shlex\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a large dataset of high impact bugs, which was created by manually reviewing four thousand issue reports in four open source projects (Ambari, Camel, Derby and Wicket). The projects were extracted from JIRA, a platform for managing reported issues.\n",
    "\n",
    "There are 1000 examples per project; there will be 4000 examples to work with in total.\n",
    "\n",
    "These projects were selected because they met the following criteria for project selection:\n",
    "\n",
    "* Target projects have a large number of (at least several thousand) reported issues , which enables the use for prediction model building and/or machine learning.\n",
    "\n",
    "* Target projects use JIRA as an issue tracking system.\n",
    "\n",
    "* Target projects are different from each other in application domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data Extraction <a class=\"anchor\" id=\"data-extraction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "\n",
    "    df = pd.read_csv(path, sep=',')\n",
    "    data = np.array(df)\n",
    "    \n",
    "    with open(path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        feature_headers = next(reader)\n",
    "    \n",
    "    data = np.insert(data, 0, feature_headers, 0)  \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Manual Feature Selection <a class=\"anchor\" id=\"manual-feature-selection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the most relevant features are selected manually. The original features included in the dataset were the following:\n",
    "\n",
    "<img src=\"./resources/images/features_in_dataset.png\" alt=\"Features in Dataset\" width=\"360\">\n",
    "\n",
    "However, after careful consideration, only the following columns will be taken into account for further analysis:\n",
    "\n",
    "| NAME | DESCRIPTION |\n",
    "|:-----|:------------|\n",
    "| `status` | Status of an issue (Resolved or Closed) |\n",
    "| `assignee` | Assignee's Name |\n",
    "| `summary` | Summary of an issue |\n",
    "| `description` | Descriptions of an issue |\n",
    "| `affected version` | Versions affected by an issue |\n",
    "| `fixed_version` | Versions of a fixed issue |\n",
    "| `votes` | Number of votes |\n",
    "| `watches` | Number of watchers |\n",
    "| `description_words` | Number of words used in description |\n",
    "| `assignee_count` | Number of assignees |\n",
    "| `comment_count` | Number of comments for an issue |\n",
    "| `commenter_count` | Number of developers who comment on an issue |\n",
    "| `commit_count` | Number of commits to resolve an issue |\n",
    "\n",
    "Criteria for manual feature filtering:\n",
    "- Actually provided in the dataset\n",
    "- Possible influence on bug priority prediction\n",
    "- Lack of data\n",
    "- Non-quantifiable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manually_selected_features(data):\n",
    "    \n",
    "    print(\"> Getting manually selecting features...\")\n",
    "    \n",
    "    # want columns 13 columns: 2, 5, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 29\n",
    "    # note: we're keeping the priority column for now\n",
    "    data = np.delete(data,(0,1,3,4,6,7,8,10,11,12,23,24,25,26,27,28,30,31), axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Data Cleaning <a class=\"anchor\" id=\"data-cleaning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where data is missing\n",
    "def clean_data(data):\n",
    "    \n",
    "    print('> Cleaning data...')\n",
    "\n",
    "    # print(\"> SIZE BEFORE CLEANING: \" + str(data.shape))\n",
    "    for i, row in enumerate(data):\n",
    "        for j, val in enumerate(row):\n",
    "            if (row[j] == 'null'):\n",
    "                # print(\"> REMOVING ROW:\\n\" + str(row))\n",
    "                data = np.delete(data, i, 0)\n",
    "                break\n",
    "\n",
    "    # print(\"> SIZE AFTER CLEANING: \" + str(data.shape))\n",
    "    print(\"> Number of examples after data cleaning: \" + str(data[1:].shape[0]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Generating New Features <a class=\"anchor\" id=\"generating-new-features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. Sentiment Analysis <a class=\"anchor\" id=\"sentiment-analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SentiStrength](http://sentistrength.wlv.ac.uk) estimates the strength of positive and negative sentiment in short texts, even for informal language. It has human-level accuracy for short social web texts in English, except political texts. SentiStrength reports two sentiment strengths:\n",
    "\n",
    "<br><center>$-1$ *(not negative)* to $-5$ *(extremely negative)*</center>\n",
    "\n",
    "<center>$1$ *(not positive)* to $5$ *(extremely positive)*</center><br>\n",
    "\n",
    "For this project, they will both be added in order to be used as a new column for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the proper paths\n",
    "sentistrength_location = \"./resources/SentiStrength/SentiStrength.jar\" # The location of SentiStrength on your computer\n",
    "sentistrength_language_folder = \"./resources/SentiStrength/data/\" # The location of the unzipped SentiStrength data files on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code tests that the above three locations are correct.\n",
    "# An error will be displayed if there is an issue.\n",
    "if not os.path.isfile(sentistrength_location):\n",
    "    print(\"SentiStrength not found at: \", sentistrength_location)\n",
    "if not os.path.isdir(sentistrength_language_folder):\n",
    "    print(\"SentiStrength data folder not found at: \", sentistrength_language_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allows SentiStrength to be called and ran on a single line of text.\n",
    "def rate_sentiment(senti_string):\n",
    "       \n",
    "    # Open a subprocess using shlex to get the command line string into the correct args list format\n",
    "    p = subprocess.Popen(shlex.split(\"java -jar '\" + sentistrength_location + \"' stdin sentidata '\" + sentistrength_language_folder + \"'\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    # Communicate via stdin the string to be rated. Note that all spaces are replaced with \"+\"\n",
    "    b = bytes(senti_string.replace(\" \",\"+\"), 'utf-8') # Can't send string in Python 3, must send bytes\n",
    "    stdout_byte, stderr_text = p.communicate(b)\n",
    "    stdout_text = stdout_byte.decode(\"utf-8\")  # Convert from byte\n",
    "    # -------- Edit - Nov 9 2017 --------\n",
    "    stdout_list = stdout_text.split(\"\\t\")      # Split by tab: ['2', '-1','\\n']\n",
    "    del stdout_list[-1]                        # Get rid of the last newline element: ['2', '-1']\n",
    "    results = list(map(int, stdout_list))      # Convert the characters to integers\n",
    "    results = results[0] + results[1]          # Combine the positive and the negative\n",
    "    # -------- END: Edit - Nov 9 2017 --------\n",
    "    #stdout_text = stdout_text.rstrip().replace(\"\\t\",\" \") # Remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1 -5\n",
    "    #return stdout_text + \" \" + senti_string\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Test to ensure that it works correctly\n",
    "print(rate_sentiment(\"i am happy but not really\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2. Fix Duration <a class=\"anchor\" id=\"fix-duration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3. Quantify Features <a class=\"anchor\" id=\"quantify-features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`status`**: {`resolved`, `closed`}\n",
    "* **`assignee`**: `string`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation <a class=\"anchor\" id=\"implementation\"></a>\n",
    "\n",
    "*Note: Automatic Feature Selection will be included here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_sigmoid(X, W, b):\n",
    "    return tf.sigmoid(tf.add(tf.matmul(X, W), b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cost(y, y_, epsilon):\n",
    "    return (-tf.reduce_mean(y * tf.log(y_ + epsilon) + (1 - y) * tf.log(1 - y_ + epsilon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this function with optional multiple layers\n",
    "def get_output_layer(X, n, k, n_perceptrons):\n",
    "    \n",
    "    # declare the weights connecting the input to the hidden layer\n",
    "    hidden_layer = {'W': tf.Variable(tf.random_normal([n, n_perceptrons])),\n",
    "                    'b': tf.Variable(tf.random_normal([n_perceptrons]))}\n",
    "\n",
    "    # declare the weights connecting the hidden layer to the output layer\n",
    "    output_layer = {'W': tf.Variable(tf.random_normal([n_perceptrons, k])),\n",
    "                    'b': tf.Variable(tf.random_normal([k]))}\n",
    "    \n",
    "    # calculate hidden layer\n",
    "    hidden_out = apply_activation_function(X, hidden_layer['W'], hidden_layer['b'])\n",
    "\n",
    "    # calculate output layer\n",
    "    y_ = apply_activation_function(hidden_out, output_layer['W'], output_layer['b'])\n",
    "    \n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(data, labels, train_perc):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size=train_perc, random_state=42)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Getting manually selecting features...\n",
      "> Cleaning data...\n",
      "> Number of examples after data cleaning: 10\n",
      "> Features considered: ['status', 'assignee', 'summary', 'description', 'affected_version', 'fixed_version', 'votes', 'watches', 'description_words', 'assingnee_count', 'comment_count', 'commenter', 'commit_count']\n"
     ]
    }
   ],
   "source": [
    "# NOTE: only using 10 examples for now\n",
    "path_all_data = \"../dataset/data_test.csv\"\n",
    "data = clean_data(manually_selected_features(get_data(path_all_data)))\n",
    "\n",
    "# extract labels (y) column from total dataset\n",
    "labels = data[1:,1]\n",
    "data = np.delete(data, 1, 1)\n",
    "\n",
    "feature_labels = [label.strip() for label in  data[0]] # remove white space around strings\n",
    "data = data[1:]\n",
    "\n",
    "train_perc = .7 # percentage of total data used for training\n",
    "x_train, x_test, y_train, y_test = split_data(data, labels, train_perc)\n",
    "m = x_train.shape[0]\n",
    "n = data.shape[1] # number of features\n",
    "k = 5 # number of classes\n",
    "\n",
    "print(\"> Features considered: \" + str(feature_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 10000 # cycles of feed forward + backprop\n",
    "epsilon = 0.000001 # used to avoid \"nan\" values from log\n",
    "\n",
    "# used to observe the change in accuracy as number of perceptrons increases\n",
    "init_perceptrons = 2\n",
    "total_perceptrons = 2\n",
    "step = 25\n",
    "\n",
    "# declare training data placeholders\n",
    "X = tf.placeholder(tf.float32, [None, n]) # input x1 and x2 (2 nodes)\n",
    "y = tf.placeholder(tf.float32, [None, k]) # output (1 node {1, 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "\n",
    "*Note: Include comparisson with other related work*\n",
    "\n",
    "| Paper | Method |\n",
    "|-------|--------|\n",
    "| [Automated Identification of High Impact Bug<br>Reports Leveraging Imbalanced Learning Strategies](http://ieeexplore.ieee.org.uproxy.library.dc-uoit.ca/stamp/stamp.jsp?arnumber=7552013&tag=1 \"Paper\") |  Naive Bayes Multinominal |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion <a class=\"anchor\" id=\"conclusion\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
