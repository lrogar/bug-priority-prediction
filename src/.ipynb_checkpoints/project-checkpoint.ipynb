{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Given any high impact bug, identify its priority.\n",
    "\n",
    "Methods in research of Software Engineering focus on predicting, localizing, and triaging bugs, but do not consider their impact or weight on the users and on the developers.\n",
    "\n",
    "For this reason, we want to distinguish different kinds of bugs by placing in them in different priority categories: **Critical**, **Blocker**, **Major**, **Minor**, **Trivial**.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Data](#data)<br>\n",
    "    1.1. [Data Extraction](#data-extraction)<br>\n",
    "    1.2. [Manual Feature Selection](#manual-feature-selection)<br>\n",
    "    1.3. [Data Cleaning](#data-cleaning)<br>\n",
    "    1.4. [Generating New Features](#generating-new-features)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.1. [Sentiment Analysis](#sentiment-analysis)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.2. [Number of Versions Affected](#number-versions)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.3. [Quantify Features](#quantify-features)<br>\n",
    "\n",
    "2. [Implementation](#implementation)<br>\n",
    "3. [Evaluation](#evaluation)<br>\n",
    "4. [Conclusion](#conclusion)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Extraction\n",
    "import csv\n",
    "\n",
    "# SentiStrength\n",
    "import subprocess\n",
    "import shlex\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a large dataset of high impact bugs, which was created by manually reviewing four thousand issue reports in four open source projects (Ambari, Camel, Derby and Wicket). The projects were extracted from JIRA, a platform for managing reported issues.\n",
    "\n",
    "There are 1000 examples per project; there will be 4000 examples to work with in total.\n",
    "\n",
    "These projects were selected because they met the following criteria for project selection:\n",
    "\n",
    "* Target projects have a large number of (at least several thousand) reported issues , which enables the use for prediction model building and/or machine learning.\n",
    "\n",
    "* Target projects use JIRA as an issue tracking system.\n",
    "\n",
    "* Target projects are different from each other in application domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data Extraction <a class=\"anchor\" id=\"data-extraction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "\n",
    "    df = pd.read_csv(path, sep=',')\n",
    "    data = np.array(df)\n",
    "    \n",
    "    with open(path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        feature_headers = next(reader)\n",
    "    \n",
    "    data = np.insert(data, 0, feature_headers, 0)  \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Manual Feature Selection <a class=\"anchor\" id=\"manual-feature-selection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the most relevant features are selected manually. The original features included in the dataset were the following:\n",
    "\n",
    "<img src=\"./resources/images/features_in_dataset.png\" alt=\"Features in Dataset\" width=\"360\">\n",
    "\n",
    "However, after careful consideration, only the following columns will be taken into account for further analysis:\n",
    "\n",
    "| NAME | DESCRIPTION |\n",
    "|:-----|:------------|\n",
    "| `status` | Status of an issue (Resolved or Closed) |\n",
    "| `assignee` | Assignee's Name |\n",
    "| `time_fixed` | Time to fix an issue (assigned to resolved) |\n",
    "| `summary` | Summary of an issue |\n",
    "| `description` | Descriptions of an issue |\n",
    "| `affected version` | Versions affected by an issue |\n",
    "| `fixed_version` | Versions of a fixed issue |\n",
    "| `votes` | Number of votes |\n",
    "| `watches` | Number of watchers |\n",
    "| `description_words` | Number of words used in description |\n",
    "| `assignee_count` | Number of assignees |\n",
    "| `comment_count` | Number of comments for an issue |\n",
    "| `commenter_count` | Number of developers who comment on an issue |\n",
    "| `commit_count` | Number of commits to resolve an issue |\n",
    "\n",
    "Criteria for manual feature filtering:\n",
    "- Actually provided in the dataset\n",
    "- Possible influence on bug priority prediction\n",
    "- Lack of data\n",
    "- Non-quantifiable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manually_selected_features(data):\n",
    "    \n",
    "    print(\"> Getting manually selecting features...\")\n",
    "    \n",
    "    # note: we're keeping the priority column for now\n",
    "    data = np.delete(data,(0,1,3,4,6,7,8,10,11,15,16,23,24,25,26,27,28,30,31), axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Data Cleaning <a class=\"anchor\" id=\"data-cleaning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rows where data is missing\n",
    "def clean_data(data):\n",
    "    \n",
    "    print('> Cleaning data...')\n",
    "\n",
    "    # print(\"> SIZE BEFORE CLEANING: \" + str(data.shape))\n",
    "    for i, row in enumerate(data):\n",
    "        for j, val in enumerate(row):\n",
    "            if (row[j] == 'null'):\n",
    "                # print(\"> REMOVING ROW:\\n\" + str(row))\n",
    "                data = np.delete(data, i, 0)\n",
    "                break\n",
    "\n",
    "    # print(\"> SIZE AFTER CLEANING: \" + str(data.shape))\n",
    "    print(\"> Number of examples after data cleaning: \" + str(data[1:].shape[0]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Generating New Features <a class=\"anchor\" id=\"generating-new-features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. Sentiment Analysis <a class=\"anchor\" id=\"sentiment-analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SentiStrength](http://sentistrength.wlv.ac.uk) estimates the strength of positive and negative sentiment in short texts, even for informal language. It has human-level accuracy for short social web texts in English, except political texts. SentiStrength reports two sentiment strengths:\n",
    "\n",
    "<br><center>$-1$ *(not negative)* to $-5$ *(extremely negative)*</center>\n",
    "\n",
    "<center>$1$ *(not positive)* to $5$ *(extremely positive)*</center><br>\n",
    "\n",
    "For this project, they will both be added in order to be used as a new column for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allows SentiStrength to be called and ran on a single line of text.\n",
    "def rate_sentiment(senti_string):\n",
    "    \n",
    "    # Set the proper paths\n",
    "    sentistrength_location = \"./resources/SentiStrength/SentiStrength.jar\" # The location of SentiStrength on your computer\n",
    "    sentistrength_language_folder = \"./resources/SentiStrength/data/\" # The location of the unzipped SentiStrength data files on your computer\n",
    "    \n",
    "    # Tests the paths are correct.\n",
    "    # An error will be displayed if there is an issue.\n",
    "    if not os.path.isfile(sentistrength_location):\n",
    "        print(\"SentiStrength not found at: \", sentistrength_location)\n",
    "    if not os.path.isdir(sentistrength_language_folder):\n",
    "        print(\"SentiStrength data folder not found at: \", sentistrength_language_folder)\n",
    "       \n",
    "    # Open a subprocess using shlex to get the command line string into the correct args list format\n",
    "    p = subprocess.Popen(shlex.split(\"java -jar '\" + sentistrength_location + \"' stdin sentidata '\" + sentistrength_language_folder + \"'\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    # Communicate via stdin the string to be rated. Note that all spaces are replaced with \"+\"\n",
    "    b = bytes(senti_string.replace(\" \",\"+\"), 'utf-8') # Can't send string in Python 3, must send bytes\n",
    "    stdout_byte, stderr_text = p.communicate(b)\n",
    "    stdout_text = stdout_byte.decode(\"utf-8\")  # Convert from byte\n",
    "    # -------- Edit - Nov 9 2017 --------\n",
    "    stdout_list = stdout_text.split(\"\\t\")      # Split by tab: ['2', '-1','\\n']\n",
    "    del stdout_list[-1]                        # Get rid of the last newline element: ['2', '-1']\n",
    "    results = list(map(int, stdout_list))      # Convert the characters to integers\n",
    "    results = results[0] + results[1]          # Combine the positive and the negative\n",
    "    # -------- END: Edit - Nov 9 2017 --------\n",
    "    #stdout_text = stdout_text.rstrip().replace(\"\\t\",\" \") # Remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1 -5\n",
    "    #return stdout_text + \" \" + senti_string\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to ensure that it works correctly\n",
    "# print(rate_sentiment(\"i am happy but not really\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a column of the data, return another that will include a representation of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_feature(strings):\n",
    "    \n",
    "    print(\"> Applying sentiment analysis...\")\n",
    "    \n",
    "    results = np.zeros(len(strings))\n",
    "    \n",
    "    for i, element in enumerate(strings):\n",
    "        results[i] = rate_sentiment(element.strip())\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2. Number of Versions Affected <a class=\"anchor\" id=\"number-versions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "**Problems:**<br>\n",
    "1. A lot of the elements under this column contain `strings`.<br>\n",
    "2. A number in the form of \"0.1.0\" cannot be converted to `float`.<br><br>\n",
    "\n",
    "*Should we just get rid of it?*\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_num_versions(v1, v2):\n",
    "    \n",
    "#     print(\"> Getting number of versions...\")\n",
    "    \n",
    "#     v1, v2 = v1.astype(np.float), v2.astype(np.float)\n",
    "#     return (np.subtract(v2, v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3. Quantify Features <a class=\"anchor\" id=\"quantify-features\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantify_status(strings):\n",
    "    \n",
    "    print(\"> Quantifying \\\"status\\\" feature...\")\n",
    "    \n",
    "    results = np.zeros(len(strings))\n",
    "    \n",
    "    for i, element in enumerate(strings):\n",
    "        if (element == \"Resolved\"):\n",
    "            results[i] = 1\n",
    "        else:\n",
    "            results[i] = 0\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "**Problem:**<br>\n",
    "Some characters in the data, under `assignee`, are not ASCII-recognizible.<br><br>\n",
    "\n",
    "*Should we edit the data manually?*\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_assignee(strings):\n",
    "    \n",
    "    print(\"> Quantifying \\\"assignee\\\" feature...\")\n",
    "    \n",
    "    results = np.zeros(len(strings))\n",
    "    names_map = {}\n",
    "    counter = 0\n",
    "    \n",
    "    for i, assignee in enumerate(strings):\n",
    "        if assignee in names_map:\n",
    "            results[i] = names_map[assignee]\n",
    "        else:\n",
    "            results[i] = counter\n",
    "            names_map[assignee] = counter\n",
    "            counter += 1\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation <a class=\"anchor\" id=\"implementation\"></a>\n",
    "\n",
    "*Note: Automatic Feature Selection will be included here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_sigmoid(X, W, b):\n",
    "    return tf.sigmoid(tf.add(tf.matmul(X, W), b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cost(y, y_, epsilon):\n",
    "    return (-tf.reduce_mean(y * tf.log(y_ + epsilon) + (1 - y) * tf.log(1 - y_ + epsilon)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "**Pending**: Implement this function with optional multiple layers\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_layer(X, n, k, n_perceptrons, n_hidden_layers=1):\n",
    "    \n",
    "    # for i in range(n_hidden_layers): # generate this name hidden layers\n",
    "        # TODO: Implement this function with optional multiple layers\n",
    "    \n",
    "    # declare the weights connecting the input to the hidden layer\n",
    "    hidden_layer = {'W': tf.Variable(tf.random_normal([n, n_perceptrons])),\n",
    "                    'b': tf.Variable(tf.random_normal([n_perceptrons]))}\n",
    "\n",
    "    # declare the weights connecting the hidden layer to the output layer\n",
    "    output_layer = {'W': tf.Variable(tf.random_normal([n_perceptrons, k])),\n",
    "                    'b': tf.Variable(tf.random_normal([k]))}\n",
    "    \n",
    "    # calculate hidden layer\n",
    "    hidden_out = apply_activation_function(X, hidden_layer['W'], hidden_layer['b'])\n",
    "\n",
    "    # calculate output layer\n",
    "    y_ = apply_activation_function(hidden_out, output_layer['W'], output_layer['b'])\n",
    "    \n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(data, labels, train_perc):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, train_size=train_perc, random_state=42)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Getting manually selecting features...\n",
      "> Cleaning data...\n",
      "> Number of examples after data cleaning: 4\n",
      "> Quantifying \"status\" feature...\n",
      "> Quantifying \"assignee\" feature...\n",
      "> Applying sentiment analysis...\n",
      "> Applying sentiment analysis...\n",
      "> Tuple example: [1.0 0.0 0.001157407 0.0 2.0 0 0 23 1 1 1 0]\n",
      "> Features considered: ['status', 'assignee', 'time_fix', 'summary', 'description', 'votes', 'watches', 'description_words', 'assingnee_count', 'comment_count', 'commenter_count', 'commit_count']\n"
     ]
    }
   ],
   "source": [
    "path_all_data = \"../dataset/data_test.csv\" # NOTE: only using 5 examples for now\n",
    "data = clean_data(manually_selected_features(get_data(path_all_data)))\n",
    "\n",
    "# extract labels (y) column from total dataset\n",
    "labels = data[1:,1]\n",
    "data = np.delete(data, 1, 1)\n",
    "\n",
    "# strip white space from features array and ignore headers in data matrix\n",
    "feature_labels = [label.strip() for label in  data[0]] # remove white space around strings\n",
    "data = data[1:]\n",
    "\n",
    "# rename some features for more descriptive names\n",
    "feature_labels = [ft.replace('assigned', 'time_fix') for ft in feature_labels]\n",
    "feature_labels = [ft.replace('commenter', 'commenter_count') for ft in feature_labels]\n",
    "\n",
    "# Quantify \"status\" (0) and \"assignee\" (1) features\n",
    "data[:,0] = quantify_status(data[:,0])\n",
    "data[:,1] = quantify_assignee(data[:,1])\n",
    "\n",
    "# Converting from string to float\n",
    "data[:,2] = data[:,2].astype(np.float)\n",
    "\n",
    "# Apply sentiment analysis to \"summary\" (3) and \"description\" (4) features\n",
    "data[:,3] = get_sentiment_feature(data[:,3])\n",
    "data[:,4] = get_sentiment_feature(data[:,4])\n",
    "\n",
    "print(\"> Tuple example: \" + str(data[0,:]))\n",
    "\n",
    "train_perc = .7 # percentage of total data used for training\n",
    "x_train, x_test, y_train, y_test = split_data(data, labels, train_perc) # randomly splitting up the data\n",
    "m = x_train.shape[0] # number of tuples for training\n",
    "n = data.shape[1] # number of features\n",
    "k = 5 # number of classes\n",
    "\n",
    "print(\"> Features considered: \" + str(feature_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 10000 # cycles of feed forward + backprop\n",
    "epsilon = 0.000001 # used to avoid \"nan\" values from log\n",
    "\n",
    "# used to observe the change in accuracy as number of perceptrons increases\n",
    "init_perceptrons = 2\n",
    "total_perceptrons = 2\n",
    "step = 25\n",
    "\n",
    "# declare training data placeholders\n",
    "X = tf.placeholder(tf.float32, [None, n]) # input x1 and x2 (2 nodes)\n",
    "y = tf.placeholder(tf.float32, [None, k]) # output (1 node {1, 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "\n",
    "*Note: Include comparisson with other related work*\n",
    "\n",
    "| Paper | Method |\n",
    "|-------|--------|\n",
    "| [Automated Identification of High Impact Bug<br>Reports Leveraging Imbalanced Learning Strategies](http://ieeexplore.ieee.org.uproxy.library.dc-uoit.ca/stamp/stamp.jsp?arnumber=7552013&tag=1 \"Paper\") |  Naive Bayes Multinominal |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion <a class=\"anchor\" id=\"conclusion\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
