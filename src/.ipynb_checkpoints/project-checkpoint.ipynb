{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Given any high impact bug, identify its priority.\n",
    "\n",
    "Methods in research of Software Engineering focus on predicting, localizing, and triaging bugs, but do not consider their impact or weight on the users and on the developers.\n",
    "\n",
    "For this reason, we want to distinguish different kinds of bugs by placing in them in different priority categories: **Critical**, **Blocker**, **Major**, **Minor**, **Trivial**.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Data](#data)<br>\n",
    "    1.1. [Data Extraction](#data-extraction)<br>\n",
    "    1.2. [Manual Feature Selection](#manual-feature-selection)<br>\n",
    "    1.3. [Data Cleaning](#data-cleaning)<br>\n",
    "    1.4. [Generating New Features](#generating-new-features)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.1. [Quantify Features](#quantify-data)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.2. [Sentiment Analysis](#sentiment-analysis)<br>\n",
    "    &nbsp;&nbsp;&nbsp;1.4.3. [Fix Duration](#fix-duration)<br>\n",
    "\n",
    "2. [Implementation](#implementation)<br>\n",
    "3. [Evaluation](#evaluation)<br>\n",
    "4. [Conclusion](#conclusion)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Extraction\n",
    "import csv\n",
    "\n",
    "# SentiStrength\n",
    "import subprocess\n",
    "import shlex\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a large dataset of high impact bugs, which was created by manually reviewing four thousand issue reports in four open source projects (Ambari, Camel, Derby and Wicket). The projects were extracted from JIRA, a platform for managing reported issues.\n",
    "\n",
    "There are 1000 examples per project; there will be 4000 examples to work with in total.\n",
    "\n",
    "These projects were selected because they met the following criteria for project selection:\n",
    "\n",
    "* Target projects have a large number of (at least several thousand) reported issues , which enables the use for prediction model building and/or machine learning.\n",
    "\n",
    "* Target projects use JIRA as an issue tracking system.\n",
    "\n",
    "* Target projects are different from each other in application domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data Extraction <a class=\"anchor\" id=\"data-extraction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_all_data = \"../dataset/data_test.csv\" # only using 10 examples\n",
    "\n",
    "df = pd.read_csv(path_all_data, sep=',')\n",
    "data = np.array(df)\n",
    "\n",
    "# TODO: Only use columns where the hand-selected features lie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Manual Feature Selection <a class=\"anchor\" id=\"manual-feature-selection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the most relevant features are selected manually. The original features included in the dataset were the following:\n",
    "\n",
    "<img src=\"./resources/images/features_in_dataset.png\" alt=\"Features in Dataset\" width=\"360\">\n",
    "\n",
    "However, after careful consideration, only the following columns will be taken into account for further analysis:\n",
    "\n",
    "| NAME | DESCRIPTION |\n",
    "|:-----|:------------|\n",
    "| `status` | Status of an issue (Resolved or Closed) |\n",
    "| `assignee` | Assignee's Name |\n",
    "| `summary` | Summary of an issue |\n",
    "| `description` | Descriptions of an issue |\n",
    "| `affected version` | Versions affected by an issue |\n",
    "| `votes` | Number of votes |\n",
    "| `watches` | Number of watchers |\n",
    "| `description_words` | Number of words used in description |\n",
    "| `assignee_count` | Number of assignees |\n",
    "| `comment_count` | Number of comments for an issue |\n",
    "| `commenter_count` | Number of developers who comment on an issue |\n",
    "| `commit_count` | Number of commits to resolve an issue |\n",
    "\n",
    "Criteria for manual feature filtering:\n",
    "- Possible influence on bug priority prediction\n",
    "- Lack of data\n",
    "- Non-quantifiable data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Data Cleaning <a class=\"anchor\" id=\"data-cleaning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SIZE BEFORE CLEANING: (10, 32)\n",
      "> REMOVING ROW:\n",
      "[226 'Bug' 'Resolved' 'Fixed' '   ' 'Minor' 'Suresh Srinivas'\n",
      " '2012/05/11 18:29:32 +0100' 'null' 'Unassigned'\n",
      " '2012/05/15 03:31:24 +0100' 3.376296296 'null'\n",
      " 'Make the daemon names and other field names consistent   '\n",
      " 'Following names need to be consistent: Hdfs -&gt; HDFS Mapreduce -&gt; MapReduce Zookeeper -&gt; ZooKeeper HADOOP -&gt; Hadoop   '\n",
      " '0.9.0' '0.9.0' 0 1 20 0 1 1 1 0 0 0 0 0 0 0 nan]\n",
      "> SIZE AFTER CLEANING: (9, 32)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where data is missing\n",
    "print(\"> SIZE BEFORE CLEANING: \" + str(data.shape))\n",
    "for i, row in enumerate(data):\n",
    "    for j, val in enumerate(row):\n",
    "        if (row[j] == 'null'):\n",
    "            print(\"> REMOVING ROW:\\n\" + str(row))\n",
    "            data = np.delete(data, i, 0)\n",
    "            break\n",
    "            \n",
    "print(\"> SIZE AFTER CLEANING: \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Generating New Features <a class=\"anchor\" id=\"generating-new-features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. Quantify Features <a class=\"anchor\" id=\"quantify-features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2. Sentiment Analysis <a class=\"anchor\" id=\"sentiment-analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SentiStrength](http://sentistrength.wlv.ac.uk) estimates the strength of positive and negative sentiment in short texts, even for informal language. It has human-level accuracy for short social web texts in English, except political texts. SentiStrength reports two sentiment strengths:\n",
    "\n",
    "<br><center>$-1$ *(not negative)* to $-5$ *(extremely negative)*</center>\n",
    "\n",
    "<center>$1$ *(not positive)* to $5$ *(extremely positive)*</center><br>\n",
    "\n",
    "For this project, they will both be added in order to be used as a new column for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the proper paths\n",
    "SentiStrengthLocation = \"./resources/SentiStrength/SentiStrength.jar\" # The location of SentiStrength on your computer\n",
    "SentiStrengthLanguageFolder = \"./resources/SentiStrength/data/\" # The location of the unzipped SentiStrength data files on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code tests that the above three locations are correct.\n",
    "# An error will be displayed if there is an issue.\n",
    "if not os.path.isfile(SentiStrengthLocation):\n",
    "    print(\"SentiStrength not found at: \", SentiStrengthLocation)\n",
    "if not os.path.isdir(SentiStrengthLanguageFolder):\n",
    "    print(\"SentiStrength data folder not found at: \", SentiStrengthLanguageFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The code below allows SentiStrength to be called and ran on a single line of text.\n",
    "def RateSentiment(sentiString):\n",
    "    # Open a subprocess using shlex to get the command line string into the correct args list format\n",
    "    p = subprocess.Popen(shlex.split(\"java -jar '\" + SentiStrengthLocation + \"' stdin sentidata '\" + SentiStrengthLanguageFolder + \"'\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    # Communicate via stdin the string to be rated. Note that all spaces are replaced with \"+\"\n",
    "    b = bytes(sentiString.replace(\" \",\"+\"), 'utf-8') # Can't send string in Python 3, must send bytes\n",
    "    stdout_byte, stderr_text = p.communicate(b)\n",
    "    stdout_text = stdout_byte.decode(\"utf-8\")  # Convert from byte\n",
    "    # -------- Edit - Nov 9 2017 --------\n",
    "    stdout_list = stdout_text.split(\"\\t\")      # Split by tab: ['2', '-1','\\n']\n",
    "    del stdout_list[-1]                        # Get rid of the last newline element: ['2', '-1']\n",
    "    results = list(map(int, stdout_list))      # Convert the characters to integers\n",
    "    results = results[0] + results[1]          # Combine the positive and the negative\n",
    "    # -------- END: Edit - Nov 9 2017 --------\n",
    "    #stdout_text = stdout_text.rstrip().replace(\"\\t\",\" \") # Remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1 -5\n",
    "    #return stdout_text + \" \" + sentiString\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Test to ensure that it works correctly\n",
    "print(RateSentiment(\"i am happy but not really\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3. Fix Duration <a class=\"anchor\" id=\"fix-duration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation <a class=\"anchor\" id=\"implementation\"></a>\n",
    "\n",
    "*Note: Automatic Feature Selection will be included here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "\n",
    "*Note: Include comparisson with other related work*\n",
    "\n",
    "| Paper | Method |\n",
    "|-------|--------|\n",
    "| [Automated Identification of High Impact Bug<br>Reports Leveraging Imbalanced Learning Strategies](http://ieeexplore.ieee.org.uproxy.library.dc-uoit.ca/stamp/stamp.jsp?arnumber=7552013&tag=1 \"Paper\") |  Naive Bayes Multinominal |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion <a class=\"anchor\" id=\"conclusion\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
